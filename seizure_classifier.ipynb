{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tsfresh.feature_extraction import feature_calculators as fc\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import linregress\n",
    "LABELS = [1, 2, 3, 4, 5]\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data.csv'\n",
    "\n",
    "df = pd.read_csv(filename, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "\n",
    "# Extract the unique subjects from all the subject time series chunks.\n",
    "subject_ids = set()\n",
    "for sub in df.index.tolist():\n",
    "    subject_ids.add('.'.join(sub.split('.')[1:]))   \n",
    "\n",
    "# Organize those unique subjects by their time series' labels (all chunk within a\n",
    "# subject have the same label, so we just look at the first chunk).\n",
    "subjects_sorted = [[] for _ in LABELS]\n",
    "for sub_id in subject_ids:\n",
    "    label = df.loc['X1.{}'.format(sub_id), 'y'].item()\n",
    "    subjects_sorted[label-1].append(sub_id)\n",
    "\n",
    "# Randomly divide the subjects into the folds, and compile those folds so that they\n",
    "# have an equal number of subject with each label in each fold.\n",
    "subject_folds = [[] for _ in range(NUM_FOLDS)]\n",
    "for subjects_label_group in subjects_sorted:\n",
    "    # Partition by walking through the shuffled list with steps of size NUM_FOLDS\n",
    "    random.shuffle(subjects_label_group)\n",
    "    subject_partitions = [subjects_label_group[i::NUM_FOLDS] for i in range(NUM_FOLDS)]\n",
    "    for j in range(NUM_FOLDS): \n",
    "        subject_folds[j] += subject_partitions[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a time_series and return its features\n",
    "def create_features(chunk):\n",
    "    feature_vector = []\n",
    "    \n",
    "    feature_vector.append(fc.mean(chunk))\n",
    "    feature_vector.append(fc.variance(chunk))\n",
    "    feature_vector.append(fc.minimum(chunk))\n",
    "    feature_vector.append(fc.median(chunk))\n",
    "    feature_vector.append(fc.maximum(chunk))\n",
    "    \n",
    "    # Welch's method to measure the density of rapid changes in signals\n",
    "    feature_vector.append(fc.mean(welch(chunk, nperseg=178)))\n",
    "    \n",
    "    # Number of times two consecutive readings are on opposite sides of the mean\n",
    "    feature_vector.append(fc.number_crossing_m(chunk, fc.mean(chunk)))\n",
    "    \n",
    "    # Slopes for each half of the time series\n",
    "    slope, _, _, _, _ = linregress(x=range(89), y=chunk[:89])\n",
    "    feature_vector.append(slope)\n",
    "    slope, _, _, _, _ = linregress(x=range(89), y=chunk[89:])\n",
    "    feature_vector.append(slope)\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cross validate\n",
    "for fold_num in range(NUM_FOLDS):\n",
    "    \n",
    "    # Split up the chunks into training and testing sets per the current testing fold\n",
    "    train_chunks = []\n",
    "    train_labels = []\n",
    "    test_chunks = []\n",
    "    test_labels = []\n",
    "    for i in range(NUM_FOLDS):\n",
    "        if fold_num == i:\n",
    "            for sub_id in subject_folds[i]:\n",
    "                for j in range(23):\n",
    "                    chunk_id = 'X{}.{}'.format(j+1, sub_id)\n",
    "                    test_chunks.append(create_features(df.loc[chunk_id, 'X1':'X178'].values))\n",
    "                    test_labels.append(1 if df.loc[chunk_id, 'y'].item() == 1 else 0)\n",
    "        else:\n",
    "            for sub_id in subject_folds[i]:\n",
    "                for j in range(23):\n",
    "                    chunk_id = 'X{}.{}'.format(j+1, sub_id)\n",
    "                    train_chunks.append(create_features(df.loc[chunk_id, 'X1':'X178'].values))\n",
    "                    train_labels.append(1 if df.loc[chunk_id, 'y'].item() == 1 else 0)\n",
    "    \n",
    "    # Train and test on LogisticRegression and ExtraTrees\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(train_chunks, train_labels)\n",
    "    extra_trees = ExtraTreesClassifier()\n",
    "    extra_trees.fit(train_chunks, train_labels)\n",
    "    \n",
    "    # Run on held out data\n",
    "    successes_seizure_log = 0\n",
    "    successes_non_seizure_log = 0\n",
    "    errors_seizure_log = 0\n",
    "    errors_non_seizure_log = 0\n",
    "    successes_seizure_trees = 0\n",
    "    successes_non_seizure_trees = 0\n",
    "    errors_seizure_trees = 0\n",
    "    errors_non_seizure_trees = 0\n",
    "    for chunk, label in zip(test_chunks, test_labels):\n",
    "        if log_reg.predict(np.asarray(chunk).reshape(1, -1)) == label:\n",
    "            if label == 1:\n",
    "                successes_seizure_log += 1\n",
    "            else: \n",
    "                successes_non_seizure_log += 1\n",
    "        else: \n",
    "            if label == 1:\n",
    "                errors_seizure_log += 1\n",
    "            else: \n",
    "                errors_non_seizure_log += 1\n",
    "                \n",
    "        if extra_trees.predict(np.asarray(chunk).reshape(1, -1)) == label:\n",
    "            if label == 1:\n",
    "                successes_seizure_trees += 1\n",
    "            else: \n",
    "                successes_non_seizure_trees += 1\n",
    "        else: \n",
    "            if label == 1:\n",
    "                errors_seizure_trees += 1\n",
    "            else: \n",
    "                errors_non_seizure_trees += 1\n",
    "    print('Fold {}'.format(fold_num))\n",
    "    print(' Log Accuracy: \\t\\t{}/{}: {}'\n",
    "          .format(successes_seizure_log + successes_non_seizure_log, \n",
    "                  len(test_chunks),\n",
    "                  round((successes_seizure_log + successes_non_seizure_log) \n",
    "                        / len(test_chunks), 4)))\n",
    "    print(' Predicted Seizure Correctly: {}'.format(successes_seizure_log))\n",
    "    print(' Predicted Seizure Incorrectly: {}'.format(errors_non_seizure_log))\n",
    "    print(' Predicted Non-Seizure Correctly: {}'.format(successes_non_seizure_log))\n",
    "    print(' Predicted Non-Seizure Incorrectly: {}'.format(errors_seizure_log))\n",
    "    \n",
    "    print(' Trees Accuracy: \\t{}/{}: {}'\n",
    "          .format(successes_seizure_trees + successes_non_seizure_trees, \n",
    "                  len(test_chunks),\n",
    "                  round((successes_seizure_trees + successes_non_seizure_trees) \n",
    "                        / len(test_chunks), 4)))\n",
    "    print(' Predicted Seizure Correctly: {}'.format(successes_seizure_trees))\n",
    "    print(' Predicted Seizure Incorrectly: {}'.format(errors_non_seizure_trees))\n",
    "    print(' Predicted Non-Seizure Correctly: {}'.format(successes_non_seizure_trees))\n",
    "    print(' Predicted Non-Seizure Incorrectly: {}'.format(errors_seizure_trees))\n",
    "    \n",
    "    # Training loss\n",
    "    errors_log = 0\n",
    "    errors_trees = 0\n",
    "    for chunk, label in zip(train_chunks, train_labels):\n",
    "        if log_reg.predict(np.asarray(chunk).reshape(1, -1)) != label:\n",
    "            errors_log += 1\n",
    "        if extra_trees.predict(np.asarray(chunk).reshape(1, -1)) != label:\n",
    "            errors_trees += 1\n",
    "    print(' Log Training Loss:\\t{}/{}: {}\\n Trees Training Loss:\\t{}/{}: {} \\n'\n",
    "          .format(errors_log, len(train_chunks),\n",
    "                  round(errors_log / len(train_chunks), 4),\n",
    "                  errors_trees, len(train_chunks),\n",
    "                  round(errors_trees / len(train_chunks), 4))) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
